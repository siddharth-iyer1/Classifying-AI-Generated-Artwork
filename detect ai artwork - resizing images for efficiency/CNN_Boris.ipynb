{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the REAL and FAKE images to 256x256"
      ],
      "metadata": {
        "id": "WoEnrvboaju-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EcQoGtvqfzce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d4011d-cc97-4227-a702-80c9596eb0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL7c-LZrXRCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ab9a77-59a1-4569-ceab-8d1d93e527e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image resizing completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "\n",
        "# Set the path to your zip file in the local session storage\n",
        "zip_path = '/content/Detect_AI_Art.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# Set the paths to the \"REAL\" and \"FAKE\" folders\n",
        "real_folder = '/content/REAL/'\n",
        "fake_folder = '/content/FAKE/'\n",
        "\n",
        "# Function to resize an image\n",
        "def resize_image(image_path, output_path, size):\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize(size)\n",
        "        img.save(output_path)\n",
        "\n",
        "# Create folders to store the resized images\n",
        "os.makedirs('/content/REAL_resized', exist_ok=True)\n",
        "os.makedirs('/content/FAKE_resized', exist_ok=True)\n",
        "\n",
        "# Resize images in the \"REAL\" folder\n",
        "for filename in os.listdir(real_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(real_folder, filename)\n",
        "        output_path = os.path.join('/content/REAL_resized', filename)\n",
        "        resize_image(image_path, output_path, (256, 256))\n",
        "\n",
        "# Resize images in the \"FAKE\" folder\n",
        "for filename in os.listdir(fake_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(fake_folder, filename)\n",
        "        output_path = os.path.join('/content/FAKE_resized', filename)\n",
        "        resize_image(image_path, output_path, (256, 256))\n",
        "\n",
        "print(\"Image resizing completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Convolutional Neural Network Architecture to Predict Real vs. AI Images\n"
      ],
      "metadata": {
        "id": "iI4vk9R-anri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set the paths to the resized image folders\n",
        "resized_folder = '/content/'\n",
        "\n",
        "# Set the image size and batch size\n",
        "img_size = (256, 256)\n",
        "batch_size = 32\n",
        "\n",
        "# Set the subset size (number of samples to use for training)\n",
        "subset_size = 1000\n",
        "\n",
        "# Create data generators for training, validation, and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators for train and validation sets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=resized_folder,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['REAL_resized', 'FAKE_resized'],\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    directory=resized_folder,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['REAL_resized', 'FAKE_resized'],\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Create generator for the test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=resized_folder,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['REAL_resized', 'FAKE_resized'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model on a subset of the data\n",
        "train_steps = subset_size // batch_size\n",
        "validation_steps = int(subset_size * 0.2) // batch_size\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb6gPQ2haywM",
        "outputId": "ecd6bbec-6e53-4a16-9474-dd24b2c3c56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2728 images belonging to 2 classes.\n",
            "Found 682 images belonging to 2 classes.\n",
            "Found 3410 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "31/31 [==============================] - 145s 5s/step - loss: 1.0991 - accuracy: 0.5310 - val_loss: 0.5087 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "31/31 [==============================] - 144s 5s/step - loss: 0.5013 - accuracy: 0.7732 - val_loss: 0.3316 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "31/31 [==============================] - 146s 5s/step - loss: 0.3492 - accuracy: 0.8589 - val_loss: 0.4071 - val_accuracy: 0.7969\n",
            "Epoch 4/10\n",
            "31/31 [==============================] - 149s 5s/step - loss: 0.2513 - accuracy: 0.8891 - val_loss: 0.1790 - val_accuracy: 0.9219\n",
            "Epoch 5/10\n",
            "31/31 [==============================] - 147s 5s/step - loss: 0.2711 - accuracy: 0.8901 - val_loss: 0.1793 - val_accuracy: 0.9375\n",
            "Epoch 6/10\n",
            "31/31 [==============================] - 146s 5s/step - loss: 0.2736 - accuracy: 0.8740 - val_loss: 0.2542 - val_accuracy: 0.8854\n",
            "Epoch 7/10\n",
            "31/31 [==============================] - 146s 5s/step - loss: 0.1737 - accuracy: 0.9335 - val_loss: 0.2657 - val_accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "31/31 [==============================] - 145s 5s/step - loss: 0.1307 - accuracy: 0.9556 - val_loss: 0.1741 - val_accuracy: 0.9323\n",
            "Epoch 9/10\n",
            "31/31 [==============================] - 143s 5s/step - loss: 0.0922 - accuracy: 0.9700 - val_loss: 0.0924 - val_accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "31/31 [==============================] - 147s 5s/step - loss: 0.1171 - accuracy: 0.9556 - val_loss: 0.1357 - val_accuracy: 0.9427\n",
            "106/106 [==============================] - 146s 1s/step - loss: 0.0932 - accuracy: 0.9661\n",
            "Test accuracy: 0.9661\n"
          ]
        }
      ]
    }
  ]
}